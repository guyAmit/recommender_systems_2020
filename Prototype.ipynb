{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yYnM4duEO7Lv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, models, datasets\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KGWtDI6zaYbH"
   },
   "outputs": [],
   "source": [
    "base_path = './movielens1m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgH7ThrgOfnS"
   },
   "outputs": [],
   "source": [
    "items_extra = os.path.join(base_path, 'items.csv')\n",
    "posters_path = os.path.join(base_path,  'posters', 'data')\n",
    "kg_id_map_path = os.path.join(base_path, 'item_id_2_kg_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tv5J1bLqbZVO"
   },
   "outputs": [],
   "source": [
    "kg_id_map_df = pandas.read_csv(kg_id_map_path)\n",
    "movielensid_to_kg_id = kg_id_map_df.set_index('item_id').to_dict()['kg_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_YRnW_07PStz"
   },
   "source": [
    "# Autoencoder - Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e8Ac6GwtPBD_"
   },
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d73Zv8evRKUp"
   },
   "outputs": [],
   "source": [
    "class SDCAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SDCAE, self).__init__()\n",
    "        #  Input size: [batch, 3, 224, 224]\n",
    "        #  Output size: [batch, 3, 224, 224]\n",
    "        self.conv1 = nn.Conv2d(3, 28, 4, stride=4, padding=0)           \n",
    "        self.conv2 = nn.Conv2d(28, 56, 4, stride=4, padding=0)          \n",
    "        self.conv3 = nn.Conv2d(56, 112, 4, stride=2, padding=0)\n",
    "\n",
    "        self.linear1 = nn.Linear(4032, 32)\n",
    "        self.linear1_t = nn.Linear(32, 4032)\n",
    "\n",
    "        self.conv3_t = nn.ConvTranspose2d(112, 56, 4, stride=2, padding=0)\n",
    "        self.conv2_t = nn.ConvTranspose2d(56, 28, 4, stride=4, padding=0)\n",
    "        self.conv1_t = nn.ConvTranspose2d(28, 3, 4, stride=4, padding=0) \n",
    "\n",
    "    def encode(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        x = F.relu(self.linear1_t(x))\n",
    "        x = x.reshape((-1, 112, 6, 6))\n",
    "        x = F.relu(self.conv3_t(x))\n",
    "        x = F.relu(self.conv2_t(x))\n",
    "        x = F.relu(self.conv1_t(x))\n",
    "        return x\n",
    "  \n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mPGDTM0chSS"
   },
   "source": [
    "# Autoencoder - Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bp2kwBUMclFB"
   },
   "outputs": [],
   "source": [
    "class SDTAE(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SDTAE, self).__init__()\n",
    "        #  Input size: [batch, 12234]\n",
    "        #  Output size: [batch, 12234]\n",
    "        self.linear1 = nn.Linear(input_size, 512)           \n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.linear3 = nn.Linear(256, 32) \n",
    "\n",
    "        self.linear_t3 = nn.Linear(32, 256)           \n",
    "        self.linear_t2 = nn.Linear(256, 512)           \n",
    "        self.linear_t1 = nn.Linear(512, input_size)\n",
    "\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        x = F.relu(self.linear_t3(x))\n",
    "        x = F.relu(self.linear_t2(x))\n",
    "        x = F.relu(self.linear_t1(x))\n",
    "        return x\n",
    "  \n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x)\n",
    "        decoded = self.decode(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YtMeQwLVchSy"
   },
   "source": [
    "# KG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KG-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZxAvv_ZchDn"
   },
   "outputs": [],
   "source": [
    "kg_train_csv = os.path.join(base_path, 'kg_train.dat')\n",
    "kg_test_csv = os.path.join(base_path, 'kg_test.dat')\n",
    "kg_valid_csv = os.path.join(base_path, 'kg_valid.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuiUwZ4HchAM"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class KG_dataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, kg_csv, entity_total):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            kg_csv (string): Dataframe file contaning KG triplets of (head tail relation).\n",
    "        \"\"\"\n",
    "        self.entity_total = entity_total\n",
    "        self.kg_data = pandas.read_csv(kg_csv, \n",
    "                                   sep='\\t',\n",
    "                                   header=None,names=['head', 'tail', 'relation'])\n",
    "    def __len__(self):\n",
    "        return len(self.kg_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        head, tail, relation = self.kg_data.iloc[idx]\n",
    "        pos_triple = (head, tail, relation)\n",
    "        head = int(head)\n",
    "        tail = int(tail)\n",
    "        relation = int(relation)\n",
    "\n",
    "        # Get negative sample for the current priple\n",
    "        neg_list = None\n",
    "        if random.random() < 0.5:\n",
    "            neg_list = self.corrupt_head_filter(pos_triple, self.entity_total) \n",
    "        else:\n",
    "            neg_list = self.corrupt_tail_filter(pos_triple, self.entity_total)\n",
    "\n",
    "        neg_head, neg_tail, neg_relation = neg_list\n",
    "        neg_head = int(neg_head)\n",
    "        neg_tail = int(neg_tail)\n",
    "        neg_relation = int(neg_relation)\n",
    "\n",
    "\n",
    "        sample = {'pos_head': head, 'pos_tail': tail, 'pos_relation': relation,\n",
    "                 'neg_head': neg_head, 'neg_tail': neg_tail, 'neg_relation': neg_relation}\n",
    "\n",
    "        return sample\n",
    "    \n",
    "\n",
    "\n",
    "    # Change the head of a triple randomly,\n",
    "    def corrupt_head_filter(self, triple, entityTotal):\n",
    "        newHead = random.randrange(entityTotal)\n",
    "        return (newHead, triple[1],triple[2])\n",
    "\n",
    "    # Change the tail of a triple randomly,\n",
    "    def corrupt_tail_filter(self, triple, entityTotal, tailDicts=None):\n",
    "        newTail = random.randrange(entityTotal)\n",
    "        return (triple[0], newTail,triple[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "suzRep7rcg-D",
    "outputId": "e1d676bb-e5c6-442d-c3b7-39aad9cc1150"
   },
   "outputs": [],
   "source": [
    "# Get entities_count and relations_count\n",
    "\n",
    "kg_train_data = pandas.read_csv(kg_train_csv, sep='\\t', header=None,names=['head', 'tail', 'relation'])\n",
    "kg_test_data = pandas.read_csv(kg_test_csv, sep='\\t', header=None,names=['head', 'tail', 'relation'])\n",
    "kg_valid_data = pandas.read_csv(kg_valid_csv, sep='\\t', header=None,names=['head', 'tail', 'relation'])\n",
    "\n",
    "entities_count = pandas.concat([kg_train_data[\"head\"],\n",
    "                            kg_test_data[\"head\"],\n",
    "                            kg_valid_data[\"head\"],\n",
    "                           kg_train_data[\"tail\"],\n",
    "                           kg_test_data[\"tail\"],\n",
    "                           kg_valid_data[\"tail\"],],axis=0).unique().max()\n",
    "\n",
    "relations_count = pandas.concat([kg_train_data[\"relation\"],\n",
    "                            kg_test_data[\"relation\"],\n",
    "                            kg_valid_data[\"relation\"]]\n",
    "                            ,axis=0).unique().max()\n",
    "\n",
    "entities_count, relations_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JHIKSe5Gcg7V"
   },
   "outputs": [],
   "source": [
    "kg_train_dataset = KG_dataset(kg_train_csv, entities_count)\n",
    "kg_test_dataset = KG_dataset(kg_test_csv, entities_count)\n",
    "kg_valid_dataset = KG_dataset(kg_valid_csv, entities_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wqplVxI8cg2b"
   },
   "outputs": [],
   "source": [
    "kg_train_loader = torch.utils.data.DataLoader(kg_train_dataset,\n",
    "                                             batch_size=512, shuffle=True,\n",
    "                                             num_workers=0)\n",
    "\n",
    "kg_valid_loader = torch.utils.data.DataLoader(kg_test_dataset,\n",
    "                                             batch_size=512, shuffle=True,\n",
    "                                             num_workers=0)\n",
    "\n",
    "kg_test_loader = torch.utils.data.DataLoader(kg_valid_dataset,\n",
    "                                             batch_size=512, shuffle=True,\n",
    "                                             num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KG - Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWj9Y2-AcgzR"
   },
   "outputs": [],
   "source": [
    "import torch.autograd as autograd\n",
    "\n",
    "\n",
    "class KG_net(nn.Module):\n",
    "    def __init__(self,\n",
    "                L1_flag,\n",
    "                embedding_size,\n",
    "                entity_total,\n",
    "                relation_total,\n",
    "                ):\n",
    "        super(KG_net, self).__init__()\n",
    "        self.L1_flag = L1_flag\n",
    "        self.embedding_size = embedding_size\n",
    "        self.ent_total = entity_total + 1\n",
    "        self.rel_total = relation_total + 1\n",
    "        use_cuda = torch.cuda.is_available()\n",
    "        self.device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "        # init user and item embeddings\n",
    "#         , padding_idx=self.ent_total-1\n",
    "        self.ent_embeddings = nn.Embedding(self.ent_total, self.embedding_size)\n",
    "\n",
    "        self.rel_embeddings = nn.Embedding(self.rel_total, self.embedding_size)\n",
    "        self.proj_embeddings = nn.Embedding(self.rel_total, self.embedding_size * self.embedding_size)\n",
    "\n",
    "        self.ent_embeddings = self.ent_embeddings.to(self.device)\n",
    "        self.rel_embeddings = self.rel_embeddings.to(self.device)\n",
    "        self.proj_embeddings = self.proj_embeddings.to(self.device)\n",
    "\n",
    "        \n",
    "  \n",
    "    def forward(self, x):\n",
    "        h, t, r = x\n",
    "\n",
    "        h = h.to(self.device)\n",
    "        t = t.to(self.device)\n",
    "        r = r.to(self.device)\n",
    "        \n",
    "        h_e = self.ent_embeddings(h)\n",
    "        t_e = self.ent_embeddings(t)\n",
    "        r_e = self.rel_embeddings(r)\n",
    "        proj_e = self.proj_embeddings(r)\n",
    "\n",
    "\n",
    "        proj_h_e = self.projection_transR_pytorch(h_e, proj_e)\n",
    "        proj_t_e = self.projection_transR_pytorch(t_e, proj_e)\n",
    "\n",
    "        if self.L1_flag:\n",
    "            score = torch.sum(torch.abs(proj_h_e + r_e - proj_t_e), 1)\n",
    "        else:\n",
    "            score = torch.sum((proj_h_e + r_e - proj_t_e) ** 2, 1)\n",
    "        \n",
    "        return score\n",
    "\n",
    "\n",
    "    def projection_transR_pytorch(self, original, proj_matrix):\n",
    "        ent_embedding_size = original.shape[1]\n",
    "        rel_embedding_size = proj_matrix.shape[1] // ent_embedding_size\n",
    "        original = original.view(-1, ent_embedding_size, 1)\n",
    "        proj_matrix = proj_matrix.view(-1, rel_embedding_size, ent_embedding_size)\n",
    "        return torch.matmul(proj_matrix, original).view(-1, rel_embedding_size)\n",
    "\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "def to_gpu(var):\n",
    "    if USE_CUDA:\n",
    "        return var.cuda()\n",
    "    return var\n",
    "\n",
    "class marginLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(marginLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pos, neg, margin):\n",
    "        zero_tensor = to_gpu(torch.FloatTensor(pos.size()))\n",
    "        zero_tensor.zero_()\n",
    "        zero_tensor = autograd.Variable(zero_tensor)\n",
    "        return torch.sum(torch.max(pos - neg + margin, zero_tensor))\n",
    "    \n",
    "    \n",
    "def normLoss(embeddings, dim=1):\n",
    "    norm = torch.sum(embeddings ** 2, dim=dim, keepdim=True)\n",
    "    return torch.sum(torch.max(norm - to_gpu(autograd.Variable(torch.FloatTensor([1.0]))), to_gpu(autograd.Variable(torch.FloatTensor([0.0])))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7UVwaoqsPEcM"
   },
   "source": [
    "# Movielens1m loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TrNHSIsPS53D"
   },
   "outputs": [],
   "source": [
    "class Movielens1m_train_dataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, rating_data, user_item_dict, items_extra_csv, img_dir,\n",
    "                 img_size, entities_count, img_transform=None,\n",
    "                 text_trasform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            rating_csv (string): Dataframe file contaning user item ratings.\n",
    "            item_extrac_csv (string)L Path to csv file containing all the items \n",
    "                extra information\n",
    "            img_dir (string): Directory with all the images.\n",
    "            img_transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "            text_trasform (callable, optional): Optional text preprocess to be\n",
    "             applied for the movie summary. Deffalt is CountVectorizer\n",
    "        \"\"\"\n",
    "        self.rating_data = rating_data\n",
    "        self.user_item_dict = user_item_dict\n",
    "        self.items_extras = pandas.read_csv(items_extra_csv)\n",
    "        self.text_list = list(self.items_extras['text_summery'])\n",
    "        self.text_transform = (CountVectorizer().fit(self.text_list).transform\n",
    "                               if text_trasform is None else text_trasform)\n",
    "        self.img_list = list(self.items_extras['img_name'])\n",
    "        self.img_size = img_size\n",
    "        self.img_dir = img_dir\n",
    "        self.img_transform = img_transform\n",
    "\n",
    "        self.unkwon_entity_idx = entities_count\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rating_data)\n",
    "\n",
    "    def __get_item_extra__(self, item_idx):\n",
    "        img_name = self.img_list[item_idx]\n",
    "        if img_name not in ['<fialed>', '<failed>']:\n",
    "            img_path = os.path.join(self.img_dir, img_name)\n",
    "            image = Image.open(img_path)\n",
    "            image = image.convert('RGB')\n",
    "            if self.img_transform is not None:\n",
    "                image = self.img_transform(image)\n",
    "        else:\n",
    "            image = torch.zeros(*self.img_size)\n",
    "\n",
    "        text = self.text_list[item_idx]\n",
    "        text = torch.from_numpy(self.text_transform([text]).todense()).float()\n",
    "\n",
    "        if int(item_idx) in movielensid_to_kg_id.keys():\n",
    "            entity = int(movielensid_to_kg_id[item_idx])\n",
    "        else:\n",
    "            entity = self.unkwon_entity_idx\n",
    "\n",
    "        return image, text.view(-1), entity\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        user, item, rating = self.rating_data.iloc[idx]\n",
    "        image, text, entity = self.__get_item_extra__(item)\n",
    "        \n",
    "        user = int(user)\n",
    "        item = int(item)\n",
    "\n",
    "        sample = {'user': user, 'item': item, 'rating': rating,\n",
    "                  'image': image, 'text': text,'entity': entity}\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zLlu7jxQZkwN"
   },
   "outputs": [],
   "source": [
    "train_csv = os.path.join(base_path, 'train.dat')\n",
    "valid_csv = os.path.join(base_path, 'valid.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = pandas.read_csv(train_csv, sep='\\t',\n",
    "                                   names=['user', 'item', 'rating'],\n",
    "                                   index_col=False)\n",
    "valid_dataframe = pandas.read_csv(valid_csv, sep='\\t',\n",
    "                                   names=['user', 'item', 'rating'],\n",
    "                                   index_col=False)\n",
    "\n",
    "test_dataframe = pandas.read_csv(valid_csv, sep='\\t',\n",
    "                                   names=['user', 'item', 'rating'],\n",
    "                                   index_col=False)\n",
    "\n",
    "rating_mean = train_dataframe['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U_g-NjOuag6o"
   },
   "outputs": [],
   "source": [
    "train_dataset = Movielens1m_train_dataset(rating_data=train_dataframe,\n",
    "                                    user_item_dict=None,\n",
    "                                    items_extra_csv=items_extra,\n",
    "                                    img_dir=posters_path,\n",
    "                                    img_size=(3, 224, 224),\n",
    "                                    entities_count=entities_count, img_transform=img_transform)\n",
    "\n",
    "valid_dataset = Movielens1m_train_dataset(rating_data=valid_dataframe,\n",
    "                                    user_item_dict=None,\n",
    "                                    items_extra_csv=items_extra,\n",
    "                                    img_dir=posters_path,\n",
    "                                    img_size=(3, 224, 224),\n",
    "                                    entities_count=entities_count, img_transform=img_transform)\n",
    "\n",
    "test_dataset = Movielens1m_train_dataset(rating_data=test_dataframe,\n",
    "                                    user_item_dict=None,\n",
    "                                    items_extra_csv=items_extra,\n",
    "                                    img_dir=posters_path,\n",
    "                                    img_size=(3, 224, 224),\n",
    "                                    entities_count=entities_count, img_transform=img_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1gQtG2rabi7K"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "cke_train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=4)\n",
    "\n",
    "cke_valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=4)\n",
    "\n",
    "cke_test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MinQHOqHcKBz"
   },
   "outputs": [],
   "source": [
    "class BuildCKE(nn.Module):\n",
    "    def __init__(self, n_users, n_items, img_net, text_net, kg_net, rating_mean, embedding_size=32):\n",
    "        super(BuildCKE, self).__init__()\n",
    "        self.img_ae = img_net\n",
    "        self.text_ae = text_net\n",
    "        self.kg_net = kg_net\n",
    "        self.user_embedding = nn.Embedding(num_embeddings=n_users,\n",
    "                                           embedding_dim=embedding_size)\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=n_items,\n",
    "                                           embedding_dim=embedding_size)\n",
    "        \n",
    "        self.user_bias = nn.Embedding(num_embeddings=n_users,\n",
    "                                           embedding_dim=1)\n",
    "        self.item_bias = nn.Embedding(num_embeddings=n_items,\n",
    "                                           embedding_dim=1)\n",
    "        self.rating_mean = rating_mean \n",
    "        \n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    def forward_train(self, inputs):\n",
    "        batch_size = inputs['entity'].size(0)\n",
    "        img_noise = noise_lambda*torch.randn(batch_size, 3, 224, 224).cuda()\n",
    "        text_noise = noise_lambda*torch.randn(batch_size, 12234).cuda()\n",
    "\n",
    "        kg_embedding = self.kg_net.ent_embeddings(inputs['entity'].cuda())\n",
    "        text_embeddding, text_recon = self.text_ae(inputs['text'].cuda()+text_noise)\n",
    "        img_embedding, img_recon = self.img_ae(inputs['image'].cuda()+img_noise)\n",
    "\n",
    "        item_id_embedding = self.item_embedding(inputs['item'].cuda())\n",
    "        \n",
    "        user_bias = self.user_bias(inputs['user'].cuda())\n",
    "        item_bias = self.item_bias(inputs['item'].cuda())\n",
    "\n",
    "\n",
    "        item_embedding = (text_embeddding+kg_embedding+\n",
    "                                  img_embedding+item_id_embedding)\n",
    "        user_embedding = self.user_embedding(inputs['user'].cuda())\n",
    "\n",
    "        preds = torch.sum(item_embedding*user_embedding, axis=1) +user_bias.squeeze(1) + item_bias.squeeze(1) + self.rating_mean\n",
    "\n",
    "        return_vals = {'preds': preds, 'img_recon': img_recon,\n",
    "                     'text_recon': text_recon, 'img_embeding': img_embedding,\n",
    "                     'text_embedding': text_embeddding, 'user_embedding': user_embedding,\n",
    "                     'item_embedding': item_id_embedding,\n",
    "                     'kg_embedding': kg_embedding}\n",
    "        return return_vals\n",
    "    \n",
    "    def forward(self, x):\n",
    "        kg_embedding = self.kg_net.ent_embeddings(x['entity'].cuda())\n",
    "        text_embeddding, _ = self.text_ae(x['text'].cuda())\n",
    "        img_embedding, _ = self.img_ae(x['image'].cuda())\n",
    "\n",
    "        item_id_embedding = self.item_embedding(x['item'].cuda())\n",
    "\n",
    "\n",
    "        item_embedding = (text_embeddding+kg_embedding+\n",
    "                                  img_embedding+item_id_embedding)\n",
    "    \n",
    "        user_embedding = self.user_embedding(x['user'].cuda())\n",
    "        \n",
    "        user_bias = self.user_bias(x['user'].cuda())\n",
    "        item_bias = self.item_bias(x['item'].cuda())\n",
    "\n",
    "\n",
    "        preds = torch.sum(item_embedding*user_embedding, axis=-1)+user_bias.squeeze(1) + item_bias.squeeze(1) + self.rating_mean\n",
    "\n",
    "        return preds\n",
    "    \n",
    "\n",
    "def tensor_norm(tensor):\n",
    "    return (tensor**2).sum()\n",
    "\n",
    "\n",
    "def eval_cke(loader, device):\n",
    "    rating_loss = nn.MSELoss()\n",
    "    cke.module.eval()\n",
    "    with torch.no_grad():\n",
    "        mse_test_loss = 0.0\n",
    "        for cke_test_inputs in loader:\n",
    "            cke_test_preds = cke(cke_test_inputs)\n",
    "            mse_loss = rating_loss(cke_test_preds, cke_test_inputs['rating'].type(torch.FloatTensor).to(device))\n",
    "            mse_test_loss += mse_loss\n",
    "        mse_test_loss = mse_test_loss/len(loader)\n",
    "        return mse_test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTroWVj4dBVj"
   },
   "outputs": [],
   "source": [
    "img_net = SDCAE()\n",
    "kg_net = KG_net(True, embedding_size=32, entity_total=entities_count,\n",
    "               relation_total=relations_count)\n",
    "text_net = SDTAE(input_size=12234)\n",
    "cke = BuildCKE(n_users=6040, n_items=3952, img_net=img_net, text_net=text_net,\n",
    "                kg_net= kg_net,  rating_mean=rating_mean, embedding_size=32)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cke = cke.to(device)\n",
    "cke = nn.DataParallel(cke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGUTg3DdvRTj"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zosq0Y_PvURO"
   },
   "source": [
    "## KG model conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e6ku1l1GvWya"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable as V\n",
    "import torch.optim as optim\n",
    "\n",
    "# model params\n",
    "relation_total = relations_count + 1\n",
    "embedding_size = 32\n",
    "\n",
    "# optimizer\n",
    "kg_learning_rate = 0.001\n",
    "\n",
    "kg_optimizer = optim.Adagrad(cke.module.kg_net.parameters(), lr=kg_learning_rate,\n",
    "                             weight_decay=1e-5)\n",
    "\n",
    "# loss\n",
    "margin = 1.0\n",
    "KG_LAMBDA = 1.0\n",
    "margin_loss = marginLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_NvdlCum5xUg"
   },
   "source": [
    "## CKE model conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NOrftGtivWvR"
   },
   "outputs": [],
   "source": [
    "noise_lambda = 0.001\n",
    "text_loss = nn.MSELoss()\n",
    "img_loss = nn.MSELoss()\n",
    "rating_loss = nn.MSELoss()\n",
    "l2_lambda = 1e-1\n",
    "cke_learning_rate = 0.001\n",
    "cke_optimizer = optim.Adam(cke.parameters(),lr=cke_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yj70BhPL4AGs"
   },
   "source": [
    "##  Traning Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='./CKE_traning_mse_bias.log' ,level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "c8B7ZIrMIsov",
    "outputId": "39d990c5-624a-4a07-c41b-378668877104"
   },
   "outputs": [],
   "source": [
    "cke.train()\n",
    "for epoch in range(2, 1000):\n",
    "    cke_training_running_loss = 0.0\n",
    "    rating_training_loss = 0.0\n",
    "    kg_training_running_loss = 0.0\n",
    "    start = time.time()\n",
    "    for inputs_cke, inputs_kg in zip(cke_train_loader, kg_train_loader):\n",
    "#         pos_inputs_cke, neg_inputs_cke = inputs_cke\n",
    "        pos_inputs_cke = inputs_cke\n",
    "\n",
    "        inputs_kg = inputs_kg\n",
    "\n",
    "      # =============Preprocessing===========\n",
    "        pos_head, pos_tail, pos_relation = inputs_kg[\"pos_head\"], inputs_kg[\"pos_tail\"], inputs_kg[\"pos_relation\"]\n",
    "        neg_head, neg_tail, neg_relation = inputs_kg[\"neg_head\"], inputs_kg[\"neg_tail\"], inputs_kg[\"neg_relation\"]\n",
    "        \n",
    "\n",
    "        # ============CKE============\n",
    "        cke_optimizer.zero_grad()\n",
    "        \n",
    "        pos_cke_outputs =  cke.module.forward_train(pos_inputs_cke)\n",
    "  \n",
    "        pos_img_recon_loss = img_loss(pos_cke_outputs['img_recon'].to(device), pos_inputs_cke['image'].to(device))\n",
    "        pos_text_recon_loss = text_loss(pos_cke_outputs['text_recon'].to(device), pos_inputs_cke['text'].to(device))\n",
    "\n",
    "\n",
    "        \n",
    "        regularization_loss = (tensor_norm(pos_cke_outputs['user_embedding']) + \n",
    "                               tensor_norm(pos_cke_outputs['img_embeding'])+\n",
    "                               tensor_norm(pos_cke_outputs['kg_embedding'])+\n",
    "                               tensor_norm(pos_cke_outputs['text_embedding'])+\n",
    "                               tensor_norm(pos_cke_outputs['item_embedding']))\n",
    "        \n",
    "        rating_mse = rating_loss(pos_cke_outputs['preds'], pos_inputs_cke['rating'].type(torch.FloatTensor).to(device))\n",
    "\n",
    "        \n",
    "        cke_loss = rating_mse + pos_img_recon_loss+ pos_text_recon_loss+ l2_lambda*regularization_loss\n",
    "        cke_training_running_loss += cke_loss\n",
    "        rating_training_loss += rating_mse\n",
    "        \n",
    "        cke_loss.backward()\n",
    "        cke_optimizer.step()\n",
    "\n",
    "        # ============KG============\n",
    "        kg_outputs_poss = cke.module.kg_net((pos_head, pos_tail, pos_relation))\n",
    "        kg_outputs_neg = cke.module.kg_net((neg_head, neg_tail, neg_relation))\n",
    "\n",
    "        kg_margin = margin_loss(kg_outputs_poss, kg_outputs_neg, margin)\n",
    "        ent_embeddings = cke.module.kg_net.ent_embeddings(torch.cat([pos_head, pos_tail, neg_head, neg_tail]).to(device))\n",
    "        rel_embeddings = cke.module.kg_net.rel_embeddings(torch.cat([pos_relation, neg_relation]).to(device))\n",
    "\n",
    "        kg_loss = kg_margin + normLoss(ent_embeddings) + normLoss(rel_embeddings)\n",
    "        kg_training_running_loss += kg_loss\n",
    "        kg_loss.backward()\n",
    "        kg_optimizer.step()\n",
    "        kg_optimizer.zero_grad()\n",
    "\n",
    "    kg_training_running_loss = kg_training_running_loss/len(cke_train_loader)\n",
    "    cke_training_running_loss = cke_training_running_loss/len(cke_train_loader)\n",
    "    rating_training_loss = rating_training_loss/len(cke_train_loader)\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        mse_test_loss = eval_cke(cke_valid_loader, device)\n",
    "        \n",
    "        end_time =  time.time()-start\n",
    "        print(f'Epoch {epoch} | Time {end_time:2f} | CKE Loss {cke_training_running_loss:2f} | KG Loss {kg_training_running_loss:2f} | Train mse loss {rating_training_loss:2f} | Test mse loss {mse_test_loss:4f}')\n",
    "        logging.info(f'Epoch {epoch} | Time {end_time:2f} | CKE Loss {cke_training_running_loss:2f} | KG Loss {kg_training_running_loss:2f} | Train mse loss {rating_training_loss:2f} | Test mse loss {mse_test_loss:4f}')\n",
    "    else:\n",
    "        end_time =  time.time()-start\n",
    "        print(f'Epoch {epoch} | Time {end_time:2f} | CKE Loss {cke_training_running_loss:2f} | KG Loss {kg_training_running_loss:2f} | Train mse loss {rating_training_loss:4f}')\n",
    "        logging.info(f'Epoch {epoch} | Time {end_time:2f} | CKE Loss {cke_training_running_loss:2f} | KG Loss {kg_training_running_loss:2f} | Train mse loss {rating_training_loss:4f}')\n",
    "   \n",
    "    if epoch % 10 == 0:\n",
    "        state = cke.module.state_dict()\n",
    "        torch.save(state, f'./models/cke_mse_bias_{epoch}_001.ckp.pth')\n",
    "        \n",
    "state = cke.module.state_dict()\n",
    "torch.save(state, './models/cke_mse_bias_1000_001.ckp.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test CKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('./models/cke_mse_bias_580_001.ckp.pth')\n",
    "cke.module.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_cke(cke_test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall and MAP evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pandas.read_csv(os.path.join(base_path, 'test_for_recall.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Movielens1m_train_dataset(rating_data=test_data,\n",
    "                                    user_item_dict=None,\n",
    "                                    items_extra_csv=items_extra,\n",
    "                                    img_dir=posters_path,\n",
    "                                    img_size=(3, 224, 224),\n",
    "                                    entities_count=entities_count, img_transform=img_transform)\n",
    "cke_test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                              batch_size=256, shuffle=False,\n",
    "                                              num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cke.module.eval()\n",
    "with torch.no_grad():\n",
    "    preds = []\n",
    "    mae_test_loss = 0.0\n",
    "    for batch_idx, cke_test_inputs in enumerate(cke_test_loader):\n",
    "        cke_test_preds = cke(cke_test_inputs)\n",
    "        preds.append(cke_test_preds)\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Finised {batch_idx} test batches')\n",
    "    preds = torch.cat(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_csv = pandas.DataFrame({'user': test_data['user'],\n",
    "                                 'item': test_data['item'],   \n",
    "                                 'True_val': test_data['True_val'],\n",
    "                                  'Preds': preds.detach().cpu().numpy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_csv.to_csv(os.path.join(base_path, 'Cke_final.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The @k evaluation itself is coded into the calc recall@k and MAP@k_v1.1 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Prototype.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
